var documenterSearchIndex = {"docs":
[{"location":"divided_differences/#Divided-differences","page":"Divided differences","title":"Divided differences","text":"","category":"section"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"The divided differences of a function f with respect to a set of interpolation points zeta_i is defined as [McCurdy]","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-def\ndivdiff(zeta_ij)f defd\nfrac12piim\noint\ndiffz\nfracf(z)(z-zeta_i)(z-zeta_i+1)(z-zeta_j)\nendequation","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"where the integral is taken along a simple contour encircling the poles once. A common approach to evaluate the divided differences of f, and an alternative definition, is the recursive scheme","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-recursive\ntagrefeqndiv-diff-def*\ndivdiff(zeta_ijz)f defd\nfracdivdiff(zeta_ij-1z)f-divdiff(zeta_ij)fz - zeta_j quad\ndivdiff(zeta_iz)f defd\nfracdivdiff(z)f-divdiff(zeta_i)fz - zeta_i quad\ndivdiff(z)f defd f(z)\nendequation","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"which, however, is prone to catastrophic cancellation for very small abszeta_i-zeta_j. This can be partially alleviated by employing BigFloats, but that will only postpone the breakdown, albeit with ~40 orders of magnitude, which might be enough for practical purposes (but much slower).","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"MatrixPolynomials.ts_div_diff_table is based upon the fact the divided differences in a third way can be computed as [McCurdy][Opitz]","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-mat-fun\ntagrefeqndiv-diff-def\ndivdiff(zeta_ij)f defd\nvece_1^top\nf(matZ_ij)\nendequation","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"i.e. the first row of the function f applied to the matrix","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"beginequation\nmatZ_ijdefd\nbmat\nzeta_i1\nzeta_i+11\nddotsddots\nddots1\nzeta_j\nendequation","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"The right-eigenvectors are given by [Opitz]","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-mat-right-eigen\nmatQ_zeta = q_ik quad\nq_ik =\nbegincases\nprod_j=i^k-1 (zeta_k - zeta_j)^-1  i  k\n1  i = k\n0  textrmelse\nendcases\nendequation","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"and similarly, the left-eigenvectors are given by","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-mat-left-eigen\ntagrefeqndiv-diff-mat-right-eigen*\nmatQ_zeta^-1 = conjq_ik quad\nconjq_ik =\nbegincases\nprod_j=i+1^k (zeta_i - zeta_j)^-1  i  k\n1  i = k\n0  textrmelse\nendcases\nendequation","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"such that","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"beginequation\ndivdiff(zeta_ij)f=\nmatQ_zetamatF_zetamatQ_zeta^-1quad\nmatF_zeta defd bmatf(zeta_i)f(zeta_i+1)ddotsf(zeta_j)\nendequation","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"However, straight evaluation of (refeqndiv-diff-mat-right-eigenrefeqndiv-diff-mat-left-eigen) is prone to the same kind of catastrophic cancellation as is eqrefeqndiv-diff-recursive, so to evaluate eqrefeqndiv-diff-mat-fun, one instead turns to Taylor or Padé expansions of f(matZ_ij) [McCurdy][Caliari], or interpolation polynomial basis changes [Zivcovich].","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"As an illustration, we show the divided differences of exp over 100 points uniformly spread over -22, calculated using eqrefeqndiv-diff-recursive, in Float64 and BigFloat precision, along with a Taylor expansion of eqrefeqndiv-diff-mat-fun:","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"(Image: Illustration of divided differences accuracy)","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"It can clearly be seen that the Taylor expansion is not susceptible to the catastrophic cancellation.","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"Thanks to the general implementation of divided differences using Taylor expansions of the desired function, it is very easy to generate Newton polynomials approximating the function on an interval:","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"julia> import MatrixPolynomials: Leja, points, NewtonPolynomial, ⏃\n\njulia> μ = 10.0 # Extent of interval\n10.0\n\njulia> m = 40 # Number of Leja points\n40\n\njulia> ζ = points(Leja(μ*range(-1,stop=1,length=1000),m))\n40-element Array{Float64,1}:\n  10.0\n -10.0\n  -0.01001001001001001\n   5.7757757757757755\n  -6.596596596596597\n   8.398398398398399\n  -8.6986986986987\n  -3.053053053053053\n   3.2132132132132134\n   9.43943943943944\n  -9.51951951951952\n  -4.794794794794795\n   7.137137137137137\n   1.5515515515515514\n  -7.757757757757758\n   9.7997997997998\n  -1.6116116116116117\n  -9.83983983983984\n   4.614614614614615\n   8.91891891891892\n  -5.7157157157157155\n   2.3723723723723724\n  -9.11911911911912\n   7.757757757757758\n  -3.873873873873874\n   6.416416416416417\n  -8.218218218218219\n   9.91991991991992\n  -0.8108108108108109\n  -9.93993993993994\n   3.973973973973974\n  -7.137137137137137\n   9.1991991991992\n  -2.3523523523523524\n   0.8108108108108109\n  -9.67967967967968\n   9.63963963963964\n   5.235235235235235\n  -5.275275275275275\n   8.078078078078079\n\njulia> d = ⏃(sin, ζ, 1, 0, 1)\n40-element Array{Float64,1}:\n -0.5440211108893093\n -0.05440211108893093\n  0.00010554419095304635\n  0.00042707706157334835\n  0.00017816519362596795\n -0.00015774261733182256\n -3.046393737965622e-6\n -1.7726427136510242e-6\n -1.2091185654301347e-7\n  8.298167162094031e-8\n  1.623156704750302e-9\n -2.1182984780033414e-9\n  3.072198477098241e-11\n  2.690974958064657e-11\n  7.708729505182354e-13\n -1.385345395017015e-13\n  2.081712029555509e-15\n  6.103669805230243e-16\n  4.2232933731665444e-18\n -2.098152059762693e-18\n  7.153277579328475e-21\n  6.390881616124369e-21\n  7.322223484376659e-23\n -1.3419887223602703e-23\n -4.050939196813086e-26\n  2.4794777140850798e-26\n  1.268544482329477e-28\n -3.581342740292682e-29\n  2.7876085130074983e-31\n  4.786776652095869e-32\n  8.943705105911237e-36\n -5.432439158165548e-35\n  9.88206793819289e-38\n  5.559232062626121e-38\n -1.2016071877913981e-41\n -4.710497689585078e-41\n  7.660823607389171e-45\n  3.728816926131357e-44\n -4.378275580359998e-48\n -2.577149389756008e-47\n\njulia> np = NewtonPolynomial(ζ, d)\nNewton polynomial of degree 39 on -10.0..10.0\n\njulia> x = range(-μ, stop=μ, length=1000)\n-10.0:0.02002002002002002:10.0\n\njulia> f_np = np.(x);\n\njulia> f_exact = sin.(x);","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"Behind the scenes, MatrixPolynomials.taylor_series is used to generate the Taylor expansion of sin(x), and when an approximation of sin(tau matZ) has been computed, the full divided difference table sin(matZ) is recovered using MatrixPolynomials.propagate_div_diff.","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"(Image: Reconstruction of sine using divided differences)","category":"page"},{"location":"divided_differences/#Reference","page":"Divided differences","title":"Reference","text":"","category":"section"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"MatrixPolynomials.⏃\nMatrixPolynomials.std_div_diff\nMatrixPolynomials.ts_div_diff_table\nMatrixPolynomials.φₖ_div_diff_basis_change\nMatrixPolynomials.div_diff_table_basis_change\nMatrixPolynomials.min_degree","category":"page"},{"location":"divided_differences/#MatrixPolynomials.⏃","page":"Divided differences","title":"MatrixPolynomials.⏃","text":"⏃(f, ζ, args...)\n\nCompute the divided differences of f at ζ, using a method that is optimized for the function f, if one is available, otherwise fallback to MatrixPolynomials.ts_div_diff_table.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.std_div_diff","page":"Divided differences","title":"MatrixPolynomials.std_div_diff","text":"std_div_diff(f, ζ, h, c, γ)\n\nCompute the divided differences of f at h*(c .+ γ*ζ), where ζ is a vector of (possibly complex) interpolation points, using the standard recursion formula.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.ts_div_diff_table","page":"Divided differences","title":"MatrixPolynomials.ts_div_diff_table","text":"ts_div_diff_table(f, ζ, h, c, γ; kwargs...)\n\nCompute the divided differences of f at h*(c .+ γ*ζ), where ζ is a vector of (possibly complex) interpolation points, by forming the full divided differences table using the Taylor series of f(H) (computed using taylor_series). If there is a scaling relationship available for f, the Taylor series of f(τ*H) is computed instead, and the full solution is recovered using propagate_div_diff.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.φₖ_div_diff_basis_change","page":"Divided differences","title":"MatrixPolynomials.φₖ_div_diff_basis_change","text":"φₖ_div_diff_basis_change(k, ζ[; θ=3.5, s=1])\n\nSpecialized interface to div_diff_table_basis_change for the φₖ functions. θ is the desired radius of convergence of the Taylor series of φₖ, and s is the scaling-and-squaring parameter, which if set to zero, will be calculated to fulfill θ.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.div_diff_table_basis_change","page":"Divided differences","title":"MatrixPolynomials.div_diff_table_basis_change","text":"div_diff_table_basis_change(f, ζ[; kwargs...])\n\nConstruct the table of divided differences of f at the interpolation points ζ, based on the algorithm on page 26 of\n\nZivcovich, F. (2019). Fast and accurate computation of divided differences for analytic functions, with an application to the exponential function. Dolomites Research Notes on Approximation, 12(1), 28–42.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.min_degree","page":"Divided differences","title":"MatrixPolynomials.min_degree","text":"min_degree(::typeof(exp), θ)\n\nMinimum degree of Taylor polynomial to represent exp to machine precision, within a circle of radius θ.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#Taylor-series","page":"Divided differences","title":"Taylor series","text":"","category":"section"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"MatrixPolynomials.TaylorSeries\nMatrixPolynomials.taylor_series\nMatrixPolynomials.closure","category":"page"},{"location":"divided_differences/#MatrixPolynomials.TaylorSeries","page":"Divided differences","title":"MatrixPolynomials.TaylorSeries","text":"TaylorSeries(d, c)\n\nRepresents the Taylor series of a function as\n\nf(x) = sum_k=0^infty c_k x^d_k\n\nwhere dₖ = d(k) and cₖ = c(k).\n\n\n\n\n\n","category":"type"},{"location":"divided_differences/#MatrixPolynomials.taylor_series","page":"Divided differences","title":"MatrixPolynomials.taylor_series","text":"taylor_series(::typeof(exp))\n\nGenerates the TaylorSeries of exp(x) = ∑ₖ x^(k) 1 / Γ(k + 1).\n\nExample\n\njulia> taylor_series(exp)\n\n1 + x + 0.5x^2 + 0.16666666666666666x^3 + ...\n\n\n\n\n\ntaylor_series(::typeof(sin))\n\nGenerates the TaylorSeries of sin(x) = ∑ₖ x^(2k + 1) (-1) ^ k / Γ(2k + 2).\n\nExample\n\njulia> taylor_series(sin)\n\nx - 0.16666666666666666x^3 + 0.008333333333333333x^5 - 0.0001984126984126984x^7 + ...\n\n\n\n\n\ntaylor_series(::typeof(cos))\n\nGenerates the TaylorSeries of cos(x) = ∑ₖ x^(2k) (-1) ^ k / Γ(2k + 1).\n\nExample\n\njulia> taylor_series(cos)\n\n1 - 0.5x^2 + 0.041666666666666664x^4 - 0.001388888888888889x^6 + ...\n\n\n\n\n\ntaylor_series(::typeof(sinh))\n\nGenerates the TaylorSeries of sinh(x) = ∑ₖ x^(2k + 1) 1 / Γ(2k + 2).\n\nExample\n\njulia> taylor_series(sinh)\n\nx + 0.16666666666666666x^3 + 0.008333333333333333x^5 + 0.0001984126984126984x^7 + ...\n\n\n\n\n\ntaylor_series(::typeof(cosh))\n\nGenerates the TaylorSeries of cosh(x) = ∑ₖ x^(2k) 1 / Γ(2k + 1).\n\nExample\n\njulia> taylor_series(cosh)\n\n1 + 0.5x^2 + 0.041666666666666664x^4 + 0.001388888888888889x^6 + ...\n\n\n\n\n\ntaylor_series(::typeof(φ₁))\n\nGenerates the TaylorSeries of φ₁(x) = ∑ₖ x^(k) 1 / Γ(k + 2).\n\nExample\n\njulia> taylor_series(φ₁)\n\n1 + 0.5x + 0.16666666666666666x^2 + 0.041666666666666664x^3 + ...\n\n\n\n\n\ntaylor_series(::Type{T}, ::typeof(exp), n; s=1, θ=3.5) where T\n\nCompute the Taylor series of exp(z/s), with n terms, or as many terms as required to achieve convergence within a circle of radius θ, whichever is largest.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.closure","page":"Divided differences","title":"MatrixPolynomials.closure","text":"closure(x::Number)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a scalar.\n\n\n\n\n\nclosure(x::Matrix)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a Matrix.\n\n\n\n\n\nclosure(x::Diagonal)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a Diagonal.\n\n\n\n\n\nclosure(x::LowerTriangular)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a LowerTriangular.\n\n\n\n\n\nclosure(x::UpperTriangular)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a UpperTriangular.\n\n\n\n\n\nclosure(x::Bidiagonal)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a UpperTriangular or LowerTriangular, depending on x.uplo.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#Scaling","page":"Divided differences","title":"Scaling","text":"","category":"section"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"For the computation of exp(A), a common approach when A is large is to compute exp(As)^s instead. This is known as scaling and squaring, if s is selected to be a power-of-two. Similar relationships can be found for other functions and are implemented for some using MatrixPolynomials.propagate_div_diff.","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"MatrixPolynomials.propagate_div_diff\nMatrixPolynomials.propagate_div_diff_sin_cos","category":"page"},{"location":"divided_differences/#MatrixPolynomials.propagate_div_diff","page":"Divided differences","title":"MatrixPolynomials.propagate_div_diff","text":"propagate_div_diff(::typeof(exp), expτH, J, args...)\n\nFind the divided differences of exp by utilizing that exp(a+b)=exp(a)exp(b).\n\n\n\n\n\npropagate_div_diff(::typeof(φ₁), φ₁H, J, H, τ)\n\nFind the divided differences of φ₁ by solving the ODE\n\ndotvecy(t) = matH vecy(t) + vece_1 quad vecy(0) = 0\n\nby iterating\n\nvecy_j+1 = vecy_j + tauvarphi_1(taumatH)(matHvecy_j + vece_1)\nquad j=0J-1\n\n\n\n\n\npropagate_div_diff(::typeof(sin), sinH, J, H, τ)\n\nFind the divided differences of sin; see propagate_div_diff_sin_cos.\n\n\n\n\n\npropagate_div_diff(::typeof(cos), cosH, J, H, τ)\n\nFind the divided differences of cos; see propagate_div_diff_sin_cos.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.propagate_div_diff_sin_cos","page":"Divided differences","title":"MatrixPolynomials.propagate_div_diff_sin_cos","text":"propagate_div_diff_sin_cos(sinH, cosH, J)\n\nFind the divided differences tables of sin and cos simultaneously, by utilizing the double-angle formulæ\n\nsin2theta = 2sinthetacostheta quad\ncos2theta = 1 - sin^2theta\n\nrecursively, doubling the angle at each iteration until the desired angle is achieved.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#Bibliography","page":"Divided differences","title":"Bibliography","text":"","category":"section"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"[Caliari]: Caliari, M. (2007). Accurate evaluation of divided differences for polynomial interpolation of exponential propagators. Computing, 80(2), 189–201. DOI: 10.1007/s00607-007-0227-1","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"[Kandolf]: Kandolf, P., Ostermann, A., & Rainer, S. (2014). A residual based error estimate for Leja interpolation of matrix functions. Linear Algebra and its Applications, 456(nil), 157–173. DOI: 10.1016/j.laa.2014.04.023","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"[McCurdy]: McCurdy, A. C., Ng, K. C., & Parlett, B. N. (1984). Accurate computation of divided differences of the exponential function. Mathematics of Computation, 43(168), 501–501. DOI: 10.1090/s0025-5718-1984-0758198-0","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"[Opitz]: Opitz, G. (1964). Steigungsmatrizen. ZAMM - Journal of Applied Mathematics and Mechanics / Zeitschrift für Angewandte Mathematik und Mechanik, 44(S1), DOI: 10.1002/zamm.19640441321","category":"page"},{"location":"divided_differences/","page":"Divided differences","title":"Divided differences","text":"[Zivcovich]: Zivcovich, F. (2019). Fast and accurate computation of divided differences for analytic functions, with an application to the exponential function. Dolomites Research Notes on Approximation, 12(1), 28–42. PDF: Zivcovich2019FAC.pdf","category":"page"},{"location":"leja/#Leja-points","page":"Leja points","title":"Leja points","text":"","category":"section"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"A common problem in polynomial interpolation of functions, is that when the number of interpolation points is increased, the interpolation polynomial becomes ill-conditioned (overfitting). It can be shown that interpolation at the roots of the Chebyshev polynomials  yields the best approximation, however, it is difficult to generate successively better approximations, since the roots of the Chebyshev polynomial of degree m are not related to those of the polynomial of degree m-1.","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"The Leja points [Leja] zeta_i are generated from a set E subset Complex such that the next point in the sequence is maximally distant from all previously generated points:","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"beginequation\nw(zeta_j)\nprod_k=0^j-1 abszeta_j-zeta_k =\nmax_zetain E\nw(zeta)\nprod_k=0^j-1\nabszeta - zeta_k\nendequation","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"with w(zeta) being an optional weight function (unity hereinafter). Interpolating a function on the Leja points largely avoids the overfitting problems and performs similarly to Chebyshev interpolation [Reichel], while still allowing for iteratively improved approximation by the addition of more interpolation points.","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"MatrixPolynomials.jl provides two methods for generating the Leja points, MatrixPolynomials.Leja and MatrixPolynomials.FastLeja. The figure below illustrates the distribution of Leja points using both methods, on the line -22, for the MatrixPolynomials.Leja, an underlying discretization of 1000 points was employed, and 10 Leja points were generated. The lower part of the plot shows the estimation of the capacity, calculated as","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"C(zeta_1m) approx\nleftleft(prod_i=1^m-1 zeta_m-zeta_iright)right^1m","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"For the set -22, the capacity is unity, which is approached for increasing values of m.","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"julia> import MatrixPolynomials: Leja, FastLeja\n\njulia> m = 10\n10\n\njulia> a,b = -2,2\n(-2, 2)\n\njulia> l = Leja(range(a, stop=b, length=1000), m)\nLeja{Float64}([-1.995995995995996, -1.991991991991992, -1.987987987987988, -1.983983983983984, -1.97997997997998, -1.975975975975976, -1.971971971971972, -1.967967967967968, -1.9639639639639639, -1.95995995995996  …  1.95995995995996, 1.9639639639639639, 1.967967967967968, 1.971971971971972, 1.975975975975976, 1.97997997997998, 1.983983983983984, 1.987987987987988, 1.991991991991992, 1.995995995995996], [2.0, -2.0, -0.002002002002002002, 1.155155155155155, -1.3193193193193193, 1.6796796796796796, -1.7397397397397398, -0.6106106106106106, 0.6426426426426426, 1.887887887887888], [0.0, 4.0, 3.9999959919879844, 3.084537289340691, 7.36488275292736, 3.118030920568761, 7.038861956228758, 7.143962613999413, 7.199339458696, 4.549146401863414])\n\njulia> fl = FastLeja(a, b, m)\nFastLeja{Float64}([2.0, -2.0, 0.0, -1.0, 1.0, -1.5, 1.5, 0.5, -1.75, 1.75], [-3.111827946268022, -1.5140533447265625, 7.91015625, -1.3255691528320312, -3.0929946899414062, 0.6718902150169015, 1.1896133422851562, 1.2691259616985917, -1.8015846004709601, 2.6076411906e-314], [-1.875, 0.25, -0.5, 1.25, -1.25, 1.625, 0.75, -1.625, 1.875, 1.5e-323], [2, 3, 4, 5, 6, 7, 8, 9, 10, 2], [9, 8, 3, 7, 4, 10, 5, 6, 1, 4570435120])","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"(Image: Leja points)","category":"page"},{"location":"leja/#Reference","page":"Leja points","title":"Reference","text":"","category":"section"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"MatrixPolynomials.Leja\nMatrixPolynomials.Leja(S::AbstractVector{T}, n::Integer) where T\nMatrixPolynomials.leja!\nMatrixPolynomials.FastLeja\nMatrixPolynomials.fast_leja!\nMatrixPolynomials.points","category":"page"},{"location":"leja/#MatrixPolynomials.Leja","page":"Leja points","title":"MatrixPolynomials.Leja","text":"Leja(S, ζ, ∏ζ)\n\nGenerate the Leja points ζ from the discretized set S; ∏ζ[i] is the product of the distances of ζ[i] to all preceding points, it can be used to estimate the capacity of the set S.\n\nThis is an implementation of the algorithm described in\n\nReichel, L. (1990). Newton Interpolation At Leja Points. BIT, 30(2), 332–346. DOI: 10.1007/bf02017352\n\n\n\n\n\n","category":"type"},{"location":"leja/#MatrixPolynomials.Leja-Union{Tuple{T}, Tuple{AbstractVector{T}, Integer}} where T","page":"Leja points","title":"MatrixPolynomials.Leja","text":"Leja(S, n)\n\nConstruct a Leja sequence generator from the discretized set S and generate n Leja points.\n\n\n\n\n\n","category":"method"},{"location":"leja/#MatrixPolynomials.leja!","page":"Leja points","title":"MatrixPolynomials.leja!","text":"leja!(l::Leja, n)\n\nGenerate n Leja points in the Leja sequence l, i.e. can be used to add more Leja points an already formed sequence. Cannot generate more Leja points than the underlying discretization l.S contains; furthermore, the quality of the Leja points may deteriorate when n approaches length(l.S).\n\n\n\n\n\n","category":"function"},{"location":"leja/#MatrixPolynomials.FastLeja","page":"Leja points","title":"MatrixPolynomials.FastLeja","text":"Leja(ζ, ∏ζ, ζs, ia, ib)\n\nGenerate the approximate Leja points ζ along a line; ∏ζ[i] is the product of the distances of ζ[i], and ζs are candidate points.\n\nThe quality of the fast Leja points for large amounts is not dependent on a preexisting discretization of a set, as is the case for Leja, however fast Leja points are restricted to lying on a line in the complex plane instead.\n\nThis is a Julia port of the Matlab algorithm published in\n\nBaglama, J., Calvetti, D., & Reichel, L. (1998). Fast Leja points. Electron. Trans. Numer. Anal, 7(124-140), 119–120.\n\n\n\n\n\n","category":"type"},{"location":"leja/#MatrixPolynomials.fast_leja!","page":"Leja points","title":"MatrixPolynomials.fast_leja!","text":"fast_leja!(fl::FastLeja, n)\n\nGenerate n fast Leja points, can be used add more fast Leja points to an already formed sequence.\n\n\n\n\n\n","category":"function"},{"location":"leja/#MatrixPolynomials.points","page":"Leja points","title":"MatrixPolynomials.points","text":"points(l::Leja)\n\nReturn the Leja points generated so far.\n\n\n\n\n\npoints(fl::FastLeja)\n\nReturn the fast Leja points generated so far.\n\n\n\n\n\n","category":"function"},{"location":"leja/#Bibliography","page":"Leja points","title":"Bibliography","text":"","category":"section"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"[Leja]: Leja, F. (1957). Sur certaines suites liées aux ensembles plans et leur application à la représentation conforme. Annales Polonici Mathematici, 4(1), 8–13. DOI: 10.4064/ap-4-1-8-13","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"[Reichel]: Reichel, L. (1990). Newton Interpolation At Leja Points. BIT, 30(2), 332–346. DOI: 10.1007/bf02017352","category":"page"},{"location":"leja/","page":"Leja points","title":"Leja points","text":"[Baglama]: Baglama, J., Calvetti, D., & Reichel, L. (1998). Fast Leja points. Electron. Trans. Numer. Anal, 7(124-140), 119–120. URL: https://elibm.org/article/10006464","category":"page"},{"location":"phi_functions/#φₖ-functions","page":"φₖ functions","title":"φₖ functions","text":"","category":"section"},{"location":"phi_functions/#Definition","page":"φₖ functions","title":"Definition","text":"","category":"section"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"These are defined recursively through","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nlabeleqnphi-k-recursive\nvarphi_0(z) defd ce^z quad\nvarphi_1(z) defd fracce^z-1z quad\nvarphi_k+1(z) defd fracvarphi_k(z)-varphi_k(0)z quad\nvarphi_k(0)=frac1k\nendequation","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"An alternate definition is","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nh^k varphi_k(hz) = int_0^h diffs\nce^(h-s)z fracs^k-1(k-1)\nendequation","category":"page"},{"location":"phi_functions/#Accuracy","page":"φₖ functions","title":"Accuracy","text":"","category":"section"},{"location":"phi_functions/#Accuracy-for-k1","page":"φₖ functions","title":"Accuracy for k=1","text":"","category":"section"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nlabeleqnphi-1-naive\nvarphi_1(z) equiv fracce^z-1z\nendequation","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"This is a common example of catastrophic cancellation; for small absz, ce^z - 1approx 0, and we thus divide a small number by a small number. By employing a trick shown by e.g.","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"Higham, N. (2002). Accuracy and stability of numerical\nalgorithms. Philadelphia: Society for Industrial and Applied\nMathematics.","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"we can substantially improve accuracy:","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nlabeleqnphi-1-accurate\nvarphi_1(z) = begincases\n1  absz  varepsilon\nfracce^z-1logce^z  varepsilon  absz  1 \nfracce^z-1z  textrmelse\nendcases\nendequation","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"(Image: Illustration of φ₁ accuracy)","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"The solid line corresponds to the naïve implementation eqrefeqnphi-1-naive, whereas the dashed line corresponds to the accurate implementation eqrefeqnphi-1-accurate.","category":"page"},{"location":"phi_functions/#Accuracy-for-k-1","page":"φₖ functions","title":"Accuracy for k  1","text":"","category":"section"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"For a Taylor expansion of a function f(x), we have","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nf(x-a) = underbracesum_i=0^n fracf^(i)(a)i (x-a)^i_defd T_n(x) +\nunderbracefracf^(n+1)(xi)(n+1)(x-a)^n+1_defd R_n(x) quad\nxi in ax\nendequation","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"We now Taylor expand ce^(h-s)z about z=0:","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nce^(h-s)z =\nsum_i=0^n fracz^i(h-s)^ii +\nfracce^(h-s)zetazeta^n+1(h-s)^n+1(n+1)\nquad abszeta leq z\nendequation","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"With this, we now calculate the definite integral appearing in the definition of varphi_k:","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nbeginaligned\nint_0^hdiffs\nce^(h-s)z s^k-1\n=\nint_0^hdiffs\nsum_i=0^n fracz^i(h-s)^is^k-1i +\nint_0^hdiffs\nfracce^(h-s)zetazeta^n+1(h-s)^n+1s^k-1(n+1) \n=\nsum_i=0^n\nfracz^ii\nint_0^hdiffs\n(h-s)^is^k-1 +\nint_0^hdiffs\nfracce^(h-s)zetazeta^n+1(h-s)^n+1s^k-1(n+1)\nendaligned\nendequation","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"For the case we are interested in, h=1 and the first integral is equivalent to Euler's beta function:","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nint_0^1diffs s^k-1(1-s)^i equiv Beta(ki+1) equiv fracGamma(k)Gamma(i+1)Gamma(k+i+1)\nendequation","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"which, for integer ki has the following value","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nBeta(ki+1) = frac(k-1)i(k+i)\nendequation","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"Inserting this into the integral (having set h=1), we find","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nlabeleqnphi-k-expansion\nvarphi_k(z) =\nsum_i=0^n\nfracz^i(k+i)\n+int_0^1diffs R_n(szeta)\nendequation","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"where we have made explicit the dependence of the Lagrange remainder R_n(szeta) on s.","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"Some numerical testing seems to indicate it is enough to set n=k in the Taylor expansion eqrefeqnphi-k-expansion to get accurate evaluation of phi_k(x) for small absx, xinmathbbR. For general z, the amount of required terms seems higher, so n is currently set to 10k.","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"(Image: Illustration of φ₁ accuracy)","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"The plot includes phi_k(z) for kin0100. To illustrate the rounding errors that would occur if one were to use the recursive definition eqrefeqnphi-k-recursive directly , we plot varphi_k(x), but for kin04 only:","category":"page"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"(Image: Illustration of φ₁ accuracy)","category":"page"},{"location":"phi_functions/#Reference","page":"φₖ functions","title":"Reference","text":"","category":"section"},{"location":"phi_functions/","page":"φₖ functions","title":"φₖ functions","text":"MatrixPolynomials.φ₁\nMatrixPolynomials.φ","category":"page"},{"location":"phi_functions/#MatrixPolynomials.φ₁","page":"φₖ functions","title":"MatrixPolynomials.φ₁","text":"φ₁(z)\n\nSpecial case of φ for k=1, taking care to avoid numerical rounding errors for small z.\n\n\n\n\n\n","category":"function"},{"location":"phi_functions/#MatrixPolynomials.φ","page":"φₖ functions","title":"MatrixPolynomials.φ","text":"φ(k, z)\n\nCompute the entire function varphi_k(z), zinmathbbC, which is recursively defined as [Eq. (2.11) of Hochbruck2010]\n\nvarphi_k+1(z) equiv fracvarphi_k(z)-varphi_k(0)z\n\nwith the base cases\n\nvarphi_0(z) = exp(z) quad\nvarphi_1(z) = fracexp(z)-1z\n\nand the special case\n\nvarphi_k(0) = frac1k\n\nThis function, as the base case φ₁, is implemented to avoid rounding errors for small z.\n\n\n\n\n\nφ(k)\n\nReturn a function corresponding to φₖ.\n\nExamples\n\njulia> φ(0)\nexp (generic function with 14 methods)\n\njulia> φ(1)\nφ₁ (generic function with 1 method)\n\njulia> φ(2)\nφ₂ (generic function with 1 method)\n\njulia> φ(15)\nφ₁₅ (generic function with 1 method)\n\njulia> φ(15)(5.0 + im)\n1.0931836313419128e-12 + 9.301475570434819e-14im\n\n\n\n\n\n","category":"function"},{"location":"newton_polynomials/#Newton-polynomials","page":"Newton polynomials","title":"Newton polynomials","text":"","category":"section"},{"location":"newton_polynomials/","page":"Newton polynomials","title":"Newton polynomials","text":"MatrixPolynomials.NewtonPolynomial\nMatrixPolynomials.NewtonPolynomial(f::Function, ζ::AbstractVector)\nMatrixPolynomials.NewtonMatrixPolynomial\nLinearAlgebra.mul!(w, nmp::MatrixPolynomials.NewtonMatrixPolynomial, A, v)","category":"page"},{"location":"newton_polynomials/#MatrixPolynomials.NewtonPolynomial","page":"Newton polynomials","title":"MatrixPolynomials.NewtonPolynomial","text":"NewtonPolynomial(ζ, d)\n\nThe unique interpolation polynomial of a function in its Newton form, i.e.\n\nf(z) approx p(z) = sum_j=1^m divdiff(zeta_1j)f prod_i=1^j-1(z - zeta_i)\n\nwhere ζ are the interpolation points and d[j]=⏃(ζ[1:j])f is the jth divided difference of the interpolated function f.\n\n\n\n\n\n","category":"type"},{"location":"newton_polynomials/#MatrixPolynomials.NewtonPolynomial-Tuple{Function, AbstractVector}","page":"Newton polynomials","title":"MatrixPolynomials.NewtonPolynomial","text":"NewtonPolynomial(f, ζ)\n\nConstruct the Newton polynomial interpolating f at ζ, automatically deriving the divided differences using ⏃.\n\n\n\n\n\n","category":"method"},{"location":"newton_polynomials/#MatrixPolynomials.NewtonMatrixPolynomial","page":"Newton polynomials","title":"MatrixPolynomials.NewtonMatrixPolynomial","text":"NewtonMatrixPolynomial(np, pv, r, Ar, error, m)\n\nThis structure aids in the computation of the action of a matrix polynomial on a vector. np is the NewtonPolynomial, pv is the desired result, r and Ar are recurrence vectors, and error is an optional error estimator algorithm that can be used to terminate the iterations early. m records how many matrix–vector multiplications were used when evaluating the matrix polynomial.\n\n\n\n\n\n","category":"type"},{"location":"newton_polynomials/#LinearAlgebra.mul!-Tuple{Any, MatrixPolynomials.NewtonMatrixPolynomial, Any, Any}","page":"Newton polynomials","title":"LinearAlgebra.mul!","text":"mul!(w, p::NewtonMatrixPolynomial, A, v)\n\nCompute the action of the NewtonMatrixPolynomial p evaluated for the matrix (or linear operator) A acting on v and storing the result in w, i.e. w ← p(A)*v.\n\n\n\n\n\n","category":"method"},{"location":"newton_polynomials/#Error-estimators","page":"Newton polynomials","title":"Error estimators","text":"","category":"section"},{"location":"newton_polynomials/","page":"Newton polynomials","title":"Newton polynomials","text":"MatrixPolynomials.NewtonMatrixPolynomialDerivative\nMatrixPolynomials.φₖResidualEstimator","category":"page"},{"location":"newton_polynomials/#MatrixPolynomials.NewtonMatrixPolynomialDerivative","page":"Newton polynomials","title":"MatrixPolynomials.NewtonMatrixPolynomialDerivative","text":"NewtonMatrixPolynomialDerivative(np, p′v, r′, Ar′, m)\n\nThis strucyture aids in the computation of the first derivative of the NewtonPolynomial np. It is to be used in lock-step with the evaluation of the polynomial, i.e. when evaluating the mth degree of np, this structure will provide the first derivative of the mth degree polynomial, storing the result in p′v. r′ and Ar′ are recurrence vectors. Its main application is in φₖResidualEstimator. m records how many matrix–vector multiplications were used when evaluating the matrix polynomial.\n\n\n\n\n\n","category":"type"},{"location":"newton_polynomials/#MatrixPolynomials.φₖResidualEstimator","page":"Newton polynomials","title":"MatrixPolynomials.φₖResidualEstimator","text":"φₖResidualEstimator{T,k}(nmpd, ρ, vscaled, estimate, tol)\n\nAn implementation of the residual error estimate of the φₖ functions, as presented in\n\nKandolf, P., Ostermann, A., & Rainer, S. (2014). A residual based error estimate for Leja interpolation of matrix functions. Linear Algebra and its Applications, 456(nil), 157–173. DOI: 10.1016/j.laa.2014.04.023\n\nnmpd is a NewtonMatrixPolynomialDerivative that successively computes the time-derivative of the NewtonMatrixPolynomial used to interpolate varphi_k(tA) (the time-step t is subsequently set to unity), ρ is the residual vector, vscaled an auxiliary vector for k>0, and estimate and tol are the estimated error and tolerance, respectively.\n\n\n\n\n\n","category":"type"},{"location":"funcv/#Functions-of-matrices","page":"Functions of matrices","title":"Functions of matrices","text":"","category":"section"},{"location":"funcv/","page":"Functions of matrices","title":"Functions of matrices","text":"MatrixPolynomials.FuncV\nMatrixPolynomials.FuncV(f::Function, A, m::Integer, t=one(eltype(A)); distribution=:leja, leja_multiplier=100, tol=1e-15, kwargs...)\nLinearAlgebra.mul!(w, funcv::MatrixPolynomials.FuncV, v)","category":"page"},{"location":"funcv/#MatrixPolynomials.FuncV","page":"Functions of matrices","title":"MatrixPolynomials.FuncV","text":"FuncV{f,T}(s⁻¹Amc, c, s)\n\nStructure for applying the action of a polynomial approximation of the function f with a matrix argument acting on a vector, i.e. w ← p(A)*v where p(z) ≈ f(z). Various properties of f may be used, such as shifting and scaling of the argument, to improve convergence and/or accuracy. s⁻¹Amc is the shifted linear operator s¹(A-c), c and s are the shift and scaling, respectively.\n\n\n\n\n\n","category":"type"},{"location":"funcv/#MatrixPolynomials.FuncV-2","page":"Functions of matrices","title":"MatrixPolynomials.FuncV","text":"FuncV(f, A, m[, t=1; distribution=:leja, kwargs...])\n\nCreate a FuncV that is used to compute f(t*A)*v using a polynomial approximation of f formed using m interpolation points.\n\nkwargs... are passed on to spectral_range which estimates the range over which f has to be interpolated.\n\n\n\n\n\n","category":"type"},{"location":"funcv/#LinearAlgebra.mul!-Tuple{Any, MatrixPolynomials.FuncV, Any}","page":"Functions of matrices","title":"LinearAlgebra.mul!","text":"mul!(w, funcv::FuncV, v)\n\nEvaluate the action of the matrix polynomial funcv on v and store the result in w.\n\n\n\n\n\n","category":"method"},{"location":"funcv/#Spectral-ranges-and-shapes","page":"Functions of matrices","title":"Spectral ranges and shapes","text":"","category":"section"},{"location":"funcv/","page":"Functions of matrices","title":"Functions of matrices","text":"MatrixPolynomials.spectral_range","category":"page"},{"location":"funcv/#MatrixPolynomials.spectral_range","page":"Functions of matrices","title":"MatrixPolynomials.spectral_range","text":"spectral_range(A[; ctol=√ε, verbosity=0])\n\nEstimate the spectral range of the matrix/linear operator A using ArnoldiMethod.jl. If the spectral range along the real/imaginary axis is smaller than ctol, it is compressed into a line. Returns a spectral Shape.\n\nExamples\n\njulia> A = Diagonal(1.0:6)\n6×6 Diagonal{Float64,StepRangeLen{Float64,Base.TwicePrecision{Float64},Base.TwicePrecision{Float64}}}:\n 1.0   ⋅    ⋅    ⋅    ⋅    ⋅\n  ⋅   2.0   ⋅    ⋅    ⋅    ⋅\n  ⋅    ⋅   3.0   ⋅    ⋅    ⋅\n  ⋅    ⋅    ⋅   4.0   ⋅    ⋅\n  ⋅    ⋅    ⋅    ⋅   5.0   ⋅\n  ⋅    ⋅    ⋅    ⋅    ⋅   6.0\n\njulia> MatrixPolynomials.spectral_range(A, verbosity=2)\nConverged: 1 of 1 eigenvalues in 6 matrix-vector products\nConverged: 1 of 1 eigenvalues in 6 matrix-vector products\nConverged: 1 of 1 eigenvalues in 6 matrix-vector products\nConverged: 1 of 1 eigenvalues in 6 matrix-vector products\n[ Info: Imaginary extent of spectral range 0.0 below tolerance 1.4901161193847656e-8, conflating.\n[ Info: 0.0 below tolerance 1.4901161193847656e-8, truncating.\n[ Info: 0.0 below tolerance 1.4901161193847656e-8, truncating.\nMatrixPolynomials.Line{Float64}(0.9999999999999998 + 0.0im, 6.0 + 0.0im)\n\njulia> MatrixPolynomials.spectral_range(exp(im*π/4)*A, verbosity=2)\nConverged: 1 of 1 eigenvalues in 6 matrix-vector products\nConverged: 1 of 1 eigenvalues in 6 matrix-vector products\nConverged: 1 of 1 eigenvalues in 6 matrix-vector products\nConverged: 1 of 1 eigenvalues in 6 matrix-vector products\nMatrixPolynomials.Rectangle{Float64}(0.7071067811865468 + 0.7071067811865478im, 4.242640687119288 + 4.242640687119283im)\n\nThe second example should also be a Line, but the algorithm is not yet clever enough.\n\n\n\n\n\nspectral_range(t, A)\n\nFinds the spectral range of t*A; if t is a vector, find the largest such range.\n\n\n\n\n\n","category":"function"},{"location":"funcv/#Shapes","page":"Functions of matrices","title":"Shapes","text":"","category":"section"},{"location":"funcv/","page":"Functions of matrices","title":"Functions of matrices","text":"The shapes in the complex plane are mainly used to generate suitable distributions of Leja points, which are in turn used to generate Newton polynomials that efficiently approximate various functions on the field-of-values of a matrix matA which is contained within the spectral shape.","category":"page"},{"location":"funcv/","page":"Functions of matrices","title":"Functions of matrices","text":"MatrixPolynomials.Shape","category":"page"},{"location":"funcv/#MatrixPolynomials.Shape","page":"Functions of matrices","title":"MatrixPolynomials.Shape","text":"Shape\n\nAbstract base type for different shapes in the complex plane encircling the spectra of linear operators.\n\n\n\n\n\n","category":"type"},{"location":"funcv/#Lines","page":"Functions of matrices","title":"Lines","text":"","category":"section"},{"location":"funcv/","page":"Functions of matrices","title":"Functions of matrices","text":"MatrixPolynomials.Line\nBase.:(*)(n::Number, l::MatrixPolynomials.Line)\nBase.range(l::MatrixPolynomials.Line, n)\nStatistics.mean(l::MatrixPolynomials.Line)\nBase.union(a::MatrixPolynomials.Line, b::MatrixPolynomials.Line)","category":"page"},{"location":"funcv/#MatrixPolynomials.Line","page":"Functions of matrices","title":"MatrixPolynomials.Line","text":"Line(a, b)\n\nFor spectra falling on a line in the complex plane from a to b.\n\n\n\n\n\n","category":"type"},{"location":"funcv/#Base.:*-Tuple{Number, MatrixPolynomials.Line}","page":"Functions of matrices","title":"Base.:*","text":"n * l::Line\n\nScale the Line l by n.\n\n\n\n\n\n","category":"method"},{"location":"funcv/#Base.range-Tuple{MatrixPolynomials.Line, Any}","page":"Functions of matrices","title":"Base.range","text":"range(l::Line, n)\n\nGenerate a uniform distribution of n values along the Line l. If the line is on the real axis, the resulting values will be real as well.\n\nExamples\n\njulia> range(MatrixPolynomials.Line(0, 1.0im), 5)\n5-element LinRange{Complex{Float64}}:\n 0.0+0.0im,0.0+0.25im,0.0+0.5im,0.0+0.75im,0.0+1.0im\n\njulia> range(MatrixPolynomials.Line(0, 1.0), 5)\n0.0:0.25:1.0\n\n\n\n\n\n","category":"method"},{"location":"funcv/#Statistics.mean-Tuple{MatrixPolynomials.Line}","page":"Functions of matrices","title":"Statistics.mean","text":"mean(l::Line)\n\nReturn the mean value along the Line l.\n\n\n\n\n\n","category":"method"},{"location":"funcv/#Base.union-Tuple{MatrixPolynomials.Line, MatrixPolynomials.Line}","page":"Functions of matrices","title":"Base.union","text":"a::Line ∪ b::Line\n\nForm the union of the Lines a and b, which need to be collinear.\n\n\n\n\n\n","category":"method"},{"location":"funcv/#Rectangles","page":"Functions of matrices","title":"Rectangles","text":"","category":"section"},{"location":"funcv/","page":"Functions of matrices","title":"Functions of matrices","text":"MatrixPolynomials.Rectangle\nBase.:(*)(n::Number, l::MatrixPolynomials.Rectangle)\nBase.range(l::MatrixPolynomials.Rectangle, n)\nStatistics.mean(l::MatrixPolynomials.Rectangle)\nBase.union(a::MatrixPolynomials.Rectangle, b::MatrixPolynomials.Rectangle)","category":"page"},{"location":"funcv/#MatrixPolynomials.Rectangle","page":"Functions of matrices","title":"MatrixPolynomials.Rectangle","text":"Rectangle(a,b)\n\nFor spectra falling within a rectangle in the complex plane with corners a and b.\n\n\n\n\n\n","category":"type"},{"location":"funcv/#Base.:*-Tuple{Number, MatrixPolynomials.Rectangle}","page":"Functions of matrices","title":"Base.:*","text":"n * r::Rectangle\n\nScale the Rectangle r by n.\n\n\n\n\n\n","category":"method"},{"location":"funcv/#Base.range-Tuple{MatrixPolynomials.Rectangle, Any}","page":"Functions of matrices","title":"Base.range","text":"range(r::Rectangle, n)\n\nGenerate a uniform distribution of n values along the diagonal of the Rectangle r.\n\nThis assumes that the eigenvalues lie on the diagonal of the rectangle, i.e. that the spread is negligible. It would be more correct to instead generate samples along the sides of the rectangle, however, spectral_range needs to be modified to correctly identify spectral ranges falling on a line that is not lying on the real or imaginary axis.\n\n\n\n\n\n","category":"method"},{"location":"funcv/#Statistics.mean-Tuple{MatrixPolynomials.Rectangle}","page":"Functions of matrices","title":"Statistics.mean","text":"mean(r::Rectangle)\n\nReturn the middle value of the Rectangle r.\n\n\n\n\n\n","category":"method"},{"location":"funcv/#Base.union-Tuple{MatrixPolynomials.Rectangle, MatrixPolynomials.Rectangle}","page":"Functions of matrices","title":"Base.union","text":"a::Rectangle ∪ b::Rectangle\n\nFind the smalling Rectangle encompassing a and b.\n\n\n\n\n\n","category":"method"},{"location":"#MatrixPolynomials.jl","page":"Home","title":"MatrixPolynomials.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The main purpose of this package is to provide polynomial approximations to f(matA), i.e. the function of a matrix matA for which the field-of-values W(matA) subset Complex (or equivalently the distribution of eigenvalues) is known a priori. If this is the case, a polynomial approximation p(z) approx f(z) for z in W(matA) can be constructed, and this can subsequently be used, substituting matA for z. This is in contrast to Krylov-based methods, where the matrix polynomials are generated on-the-fly, without any prior knowledge of W(matA) (even though knowledge can be used to speed up the convergence of the Krylov iterations).","category":"page"},{"location":"#Index","page":"Home","title":"Index","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
