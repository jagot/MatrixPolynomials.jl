var documenterSearchIndex = {"docs":
[{"location":"divided_differences/#Divided-differences-1","page":"Divided differences","title":"Divided differences","text":"","category":"section"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"The divided differences of a function f with respect to a set of interpolation points zeta_i is defined as (McCurdy 1984)","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-def\ndivdiff(zeta_ij)f defd\nfrac12piim\noint\ndiffz\nfracf(z)(z-zeta_i)(z-zeta_i+1)(z-zeta_j)\nendequation","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"where the integral is taken along a simple contour encircling the poles once. A common approach to evaluate the divided differences of f, and an alternative definition, is the recursive scheme","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-recursive\ntagrefeqndiv-diff-def*\ndivdiff(zeta_ijz)f defd\nfracdivdiff(zeta_ij-1z)f-divdiff(zeta_ij)fz - zeta_j quad\ndivdiff(zeta_iz)f defd\nfracdivdiff(z)f-divdiff(zeta_i)fz - zeta_i quad\ndivdiff(z)f defd f(z)\nendequation","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"which, however, is prone to catastrophic cancellation for very small abszeta_i-zeta_j. This can be partially alleviated by employing BigFloats, but that will only postpone the breakdown, albeit with ~40 orders of magnitude, which might be enough for practical purposes (but much slower).","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"MatrixPolynomials.ts_div_diff_table is based upon the fact the divided differences in a third way can be computed as (McCurdy 1984, Opitz 1964)","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-mat-fun\ntagrefeqndiv-diff-def\ndivdiff(zeta_ij)f defd\nvece_1^top\nf(matZ_ij)\nendequation","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"i.e. the first row of the function f applied to the matrix","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"beginequation\nmatZ_ijdefd\nbmat\nzeta_i1\nzeta_i+11\nddotsddots\nddots1\nzeta_j\nendequation","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"The right-eigenvectors are given by (Opitz 1964)","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-mat-right-eigen\nmatQ_zeta = q_ik quad\nq_ik =\nbegincases\nprod_j=i^k-1 (zeta_k - zeta_j)^-1  i  k\n1  i = k\n0  textrmelse\nendcases\nendequation","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"and similarly, the left-eigenvectors are given by","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"beginequation\nlabeleqndiv-diff-mat-left-eigen\ntagrefeqndiv-diff-mat-right-eigen*\nmatQ_zeta^-1 = conjq_ik quad\nconjq_ik =\nbegincases\nprod_j=i+1^k (zeta_i - zeta_j)^-1  i  k\n1  i = k\n0  textrmelse\nendcases\nendequation","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"such that","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"beginequation\ndivdiff(zeta_ij)f=\nmatQ_zetamatF_zetamatQ_zeta^-1quad\nmatF_zeta defd bmatf(zeta_i)f(zeta_i+1)ddotsf(zeta_j)\nendequation","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"However, straight evaluation of (refeqndiv-diff-mat-right-eigenrefeqndiv-diff-mat-left-eigen) is prone to the same kind of catastrophic cancellation as is eqrefeqndiv-diff-recursive, so to evaluate eqrefeqndiv-diff-mat-fun, one instead turns to Taylor or Padé expansions of f(matZ_ij) (McCurdy 1984, Caliari 2004), or interpolation polynomial basis changes (Zivcovich 2019).","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"As an illustration, we show the divided differences of exp over 100 points uniformly spread over -22, calculated using eqrefeqndiv-diff-recursive, in Float64 and BigFloat precision, along with a Taylor expansion of eqrefeqndiv-diff-mat-fun:","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"(Image: Illustration of divided differences accuracy)","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"It can clearly be seen that the Taylor expansion is not susceptible to the catastrophic cancellation.","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"Thanks to the general implementation of divided differences using Taylor expansions of the desired function, it is very easy to generate Newton polynomials approximating the function on an interval:","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"julia> import MatrixPolynomials: Leja, points, NewtonPolynomial, ⏃\n\njulia> μ = 10.0 # Extent of interval\n10.0\n\njulia> m = 40 # Number of Leja points\n40\n\njulia> ζ = points(Leja(μ*range(-1,stop=1,length=1000),m))\n40-element Array{Float64,1}:\n  10.0\n -10.0\n  -0.01001001001001001\n   5.7757757757757755\n  -6.596596596596597\n   8.398398398398399\n  -8.6986986986987\n  -3.053053053053053\n   3.2132132132132134\n   9.43943943943944\n  -9.51951951951952\n  -4.794794794794795\n   7.137137137137137\n   1.5515515515515514\n  -7.757757757757758\n   9.7997997997998\n  -1.6116116116116117\n  -9.83983983983984\n   4.614614614614615\n   8.91891891891892\n  -5.7157157157157155\n   2.3723723723723724\n  -9.11911911911912\n   7.757757757757758\n  -3.873873873873874\n   6.416416416416417\n  -8.218218218218219\n   9.91991991991992\n  -0.8108108108108109\n  -9.93993993993994\n   3.973973973973974\n  -7.137137137137137\n   9.1991991991992\n  -2.3523523523523524\n   0.8108108108108109\n  -9.67967967967968\n   9.63963963963964\n   5.235235235235235\n  -5.275275275275275\n   8.078078078078079\n\njulia> d = ⏃(sin, ζ, 1, 0, 1)\n40-element Array{Float64,1}:\n -0.5440211108893093\n -0.05440211108893093\n  0.00010554419095304635\n  0.00042707706157334835\n  0.00017816519362596795\n -0.00015774261733182256\n -3.046393737965622e-6\n -1.7726427136510242e-6\n -1.2091185654301347e-7\n  8.298167162094031e-8\n  1.623156704750302e-9\n -2.1182984780033414e-9\n  3.072198477098241e-11\n  2.690974958064657e-11\n  7.708729505182354e-13\n -1.385345395017015e-13\n  2.081712029555509e-15\n  6.103669805230243e-16\n  4.2232933731665444e-18\n -2.098152059762693e-18\n  7.153277579328475e-21\n  6.390881616124369e-21\n  7.322223484376659e-23\n -1.3419887223602703e-23\n -4.050939196813086e-26\n  2.4794777140850798e-26\n  1.268544482329477e-28\n -3.581342740292682e-29\n  2.7876085130074983e-31\n  4.786776652095869e-32\n  8.943705105911237e-36\n -5.432439158165548e-35\n  9.88206793819289e-38\n  5.559232062626121e-38\n -1.2016071877913981e-41\n -4.710497689585078e-41\n  7.660823607389171e-45\n  3.728816926131357e-44\n -4.378275580359998e-48\n -2.577149389756008e-47\n\njulia> np = NewtonPolynomial(ζ, d);","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"Behind the scenes, MatrixPolynomials.taylor_series is used to generate the Taylor expansion of sin(x), and when an approximation of sin(tau matZ), the full divided difference sin(matZ) table is recovered using MatrixPolynomials.propagate_div_diff.","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"(Image: Reconstruction of sine using divided differences)","category":"page"},{"location":"divided_differences/#Reference-1","page":"Divided differences","title":"Reference","text":"","category":"section"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"MatrixPolynomials.⏃\nMatrixPolynomials.std_div_diff\nMatrixPolynomials.ts_div_diff_table\nMatrixPolynomials.φₖ_div_diff_basis_change\nMatrixPolynomials.div_diff_table_basis_change\nMatrixPolynomials.min_degree","category":"page"},{"location":"divided_differences/#MatrixPolynomials.⏃","page":"Divided differences","title":"MatrixPolynomials.⏃","text":"⏃(f, ζ, args...)\n\nCompute the divided differences of f at ζ, using a method that is optimized for the function f, if one is available, otherwise fallback to MatrixPolynomials.ts_div_diff_table.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.std_div_diff","page":"Divided differences","title":"MatrixPolynomials.std_div_diff","text":"std_div_diff(f, ζ, h, c, γ)\n\nCompute the divided differences of f at h*(c .+ γ*ζ), where ζ is a vector of (possibly complex) interpolation points, using the standard recursion formula.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.ts_div_diff_table","page":"Divided differences","title":"MatrixPolynomials.ts_div_diff_table","text":"ts_div_diff_table(f, ζ, h, c, γ; kwargs...)\n\nCompute the divided differences of f at h*(c .+ γ*ζ), where ζ is a vector of (possibly complex) interpolation points, by forming the full divided differences table using the Taylor series of f(H) (computed using taylor_series). If there is a scaling relationship available for f, the Taylor series of f(τ*H) is computed instead, and the full solution is recovered using propagate_div_diff.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.φₖ_div_diff_basis_change","page":"Divided differences","title":"MatrixPolynomials.φₖ_div_diff_basis_change","text":"φₖ_div_diff_basis_change(k, ζ[; θ=3.5, s=1])\n\nSpecialized interface to div_diff_table_basis_change for the φₖ functions. θ is the desired radius of convergence of the Taylor series of φₖ, and s is the scaling-and-squaring parameter, which if set to zero, will be calculated to fulfill θ.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.div_diff_table_basis_change","page":"Divided differences","title":"MatrixPolynomials.div_diff_table_basis_change","text":"div_diff_table_basis_change(f, ζ[; kwargs...])\n\nConstruct the table of divided differences of f at the interpolation points ζ, based on the algorithm on page 26 of\n\nZivcovich, F. (2019). Fast and accurate computation of divided differences for analytic functions, with an application to the exponential function. Dolomites Research Notes on Approximation, 12(1), 28–42.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.min_degree","page":"Divided differences","title":"MatrixPolynomials.min_degree","text":"min_degree(::typeof(exp), θ)\n\nMinimum degree of Taylor polynomial to represent exp to machine precision, within a circle of radius θ.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#Taylor-series-1","page":"Divided differences","title":"Taylor series","text":"","category":"section"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"MatrixPolynomials.TaylorSeries\nMatrixPolynomials.taylor_series\nMatrixPolynomials.closure","category":"page"},{"location":"divided_differences/#MatrixPolynomials.TaylorSeries","page":"Divided differences","title":"MatrixPolynomials.TaylorSeries","text":"TaylorSeries(d, c)\n\nRepresents the Taylor series of a function as\n\nf(x) = sum_k=0^infty c_k x^d_k\n\nwhere dₖ = d(k) and cₖ = c(k).\n\n\n\n\n\n","category":"type"},{"location":"divided_differences/#MatrixPolynomials.taylor_series","page":"Divided differences","title":"MatrixPolynomials.taylor_series","text":"taylor_series(::typeof(exp))\n\nGenerates the TaylorSeries of exp(x) = ∑ₖ x^(k) 1 / Γ(k + 1).\n\nExample\n\njulia> taylor_series(exp)\n\n1 + x + 0.5x^2 + 0.16666666666666666x^3 + ...\n\n\n\n\n\ntaylor_series(::typeof(sin))\n\nGenerates the TaylorSeries of sin(x) = ∑ₖ x^(2k + 1) (-1) ^ k / Γ(2k + 2).\n\nExample\n\njulia> taylor_series(sin)\n\nx - 0.16666666666666666x^3 + 0.008333333333333333x^5 - 0.0001984126984126984x^7 + ...\n\n\n\n\n\ntaylor_series(::typeof(cos))\n\nGenerates the TaylorSeries of cos(x) = ∑ₖ x^(2k) (-1) ^ k / Γ(2k + 1).\n\nExample\n\njulia> taylor_series(cos)\n\n1 - 0.5x^2 + 0.041666666666666664x^4 - 0.001388888888888889x^6 + ...\n\n\n\n\n\ntaylor_series(::typeof(sinh))\n\nGenerates the TaylorSeries of sinh(x) = ∑ₖ x^(2k + 1) 1 / Γ(2k + 2).\n\nExample\n\njulia> taylor_series(sinh)\n\nx + 0.16666666666666666x^3 + 0.008333333333333333x^5 + 0.0001984126984126984x^7 + ...\n\n\n\n\n\ntaylor_series(::typeof(cosh))\n\nGenerates the TaylorSeries of cosh(x) = ∑ₖ x^(2k) 1 / Γ(2k + 1).\n\nExample\n\njulia> taylor_series(cosh)\n\n1 + 0.5x^2 + 0.041666666666666664x^4 + 0.001388888888888889x^6 + ...\n\n\n\n\n\ntaylor_series(::typeof(φ₁))\n\nGenerates the TaylorSeries of φ₁(x) = ∑ₖ x^(k) 1 / Γ(k + 2).\n\nExample\n\njulia> taylor_series(φ₁)\n\n1 + 0.5x + 0.16666666666666666x^2 + 0.041666666666666664x^3 + ...\n\n\n\n\n\ntaylor_series(::Type{T}, ::typeof(exp), n; s=1, θ=3.5) where T\n\nCompute the Taylor series of exp(z/s), with n terms, or as many terms as required to achieve convergence within a circle of radius θ, whichever is largest.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.closure","page":"Divided differences","title":"MatrixPolynomials.closure","text":"closure(x::Number)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a scalar.\n\n\n\n\n\nclosure(x::Matrix)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a Matrix.\n\n\n\n\n\nclosure(x::Diagonal)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a Diagonal.\n\n\n\n\n\nclosure(x::LowerTriangular)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a LowerTriangular.\n\n\n\n\n\nclosure(x::UpperTriangular)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a UpperTriangular.\n\n\n\n\n\nclosure(x::Bidiagonal)\n\nGenerates the closure type of xⁿ as n → ∞, i.e. a UpperTriangular or LowerTriangular, depending on x.uplo.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#Scaling-1","page":"Divided differences","title":"Scaling","text":"","category":"section"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"For the computation of exp(A), a common approach when A is large is to compute exp(As)^s instead. This is known as scaling and squaring, if s is selected to be a power-of-two. Similar relationships can be found for other functions and are implemented for some using MatrixPolynomials.propagate_div_diff.","category":"page"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"MatrixPolynomials.propagate_div_diff\nMatrixPolynomials.propagate_div_diff_sin_cos","category":"page"},{"location":"divided_differences/#MatrixPolynomials.propagate_div_diff","page":"Divided differences","title":"MatrixPolynomials.propagate_div_diff","text":"propagate_div_diff(::typeof(exp), expτH, J, args...)\n\nFind the divided differences of exp by utilizing that exp(a+b)=exp(a)exp(b).\n\n\n\n\n\npropagate_div_diff(::typeof(φ₁), φ₁H, J, H, τ)\n\nFind the divided differences of φ₁ by solving the ODE\n\ndotvecy(t) = matH vecy(t) + vece_1 quad vecy(0) = 0\n\nby iterating\n\nvecy_j+1 = vecy_j + tauvarphi_1(taumatH)(matHvecy_j + vece_1)\nquad j=0J-1\n\n\n\n\n\npropagate_div_diff(::typeof(sin), sinH, J, H, τ)\n\nFind the divided differences of sin; see propagate_div_diff_sin_cos.\n\n\n\n\n\npropagate_div_diff(::typeof(cos), cosH, J, H, τ)\n\nFind the divided differences of cos; see propagate_div_diff_sin_cos.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#MatrixPolynomials.propagate_div_diff_sin_cos","page":"Divided differences","title":"MatrixPolynomials.propagate_div_diff_sin_cos","text":"propagate_div_diff_sin_cos(sinH, cosH, J)\n\nFind the divided differences tables of sin and cos simultaneously, by utilizing the double-angle formulas\n\nsin2theta = 2sinthetacostheta quad\ncos2theta = 1 - sin^2theta\n\nrecursively, doubling the angle at each iteration until the desired angle is achieved.\n\n\n\n\n\n","category":"function"},{"location":"divided_differences/#Bibliography-1","page":"Divided differences","title":"Bibliography","text":"","category":"section"},{"location":"divided_differences/#","page":"Divided differences","title":"Divided differences","text":"Caliari, M. (2007). Accurate evaluation of divided differences for polynomial interpolation of exponential propagators. Computing, 80(2), 189–201. DOI: 10.1007/s00607-007-0227-1\nKandolf, P., Ostermann, A., & Rainer, S. (2014). A residual based error estimate for leja interpolation of matrix functions. Linear Algebra and its Applications, 456(nil), 157–173. DOI: 10.1016/j.laa.2014.04.023\nMcCurdy, A. C., Ng, K. C., & Parlett, B. N. (1984). Accurate computation of divided differences of the exponential function. Mathematics of Computation, 43(168), 501–501. DOI: 10.1090/s0025-5718-1984-0758198-0\nOpitz, G. (1964). Steigungsmatrizen. ZAMM - Journal of Applied Mathematics and Mechanics / Zeitschrift für Angewandte Mathematik und Mechanik, 44(S1), DOI: 10.1002/zamm.19640441321\nZivcovich, F. (2019). Fast and accurate computation of divided differences for analytic functions, with an application to the exponential function. Dolomites Research Notes on Approximation, 12(1), 28–42. PDF: Zivcovich2019FAC.pdf","category":"page"},{"location":"phi_functions/#φₖ-functions-1","page":"φₖ functions","title":"φₖ functions","text":"","category":"section"},{"location":"phi_functions/#Definition-1","page":"φₖ functions","title":"Definition","text":"","category":"section"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"These are defined recursively through","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nlabeleqnphi-k-recursive\nvarphi_0(z) defd ce^z quad\nvarphi_1(z) defd fracce^z-1z quad\nvarphi_k+1(z) defd fracvarphi_k(z)-varphi_k(0)z quad\nvarphi_k(0)=frac1k\nendequation","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"An alternate definition is","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nh^k varphi_k(hz) = int_0^h diffs\nce^(h-s)z fracs^k-1(k-1)\nendequation","category":"page"},{"location":"phi_functions/#Accuracy-1","page":"φₖ functions","title":"Accuracy","text":"","category":"section"},{"location":"phi_functions/#Accuracy-for-k1-1","page":"φₖ functions","title":"Accuracy for k=1","text":"","category":"section"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nlabeleqnphi-1-naive\nvarphi_1(z) equiv fracce^z-1z\nendequation","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"This is a common example of catastrophic cancellation; for small absz, ce^z - 1approx 0, and we thus divide a small number by a small number. By employing a trick shown by e.g.","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"Higham, N. (2002). Accuracy and stability of numerical\nalgorithms. Philadelphia: Society for Industrial and Applied\nMathematics.","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"we can substantially improve accuracy:","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nlabeleqnphi-1-accurate\nvarphi_1(z) = begincases\n1  absz  varepsilon\nfracce^z-1logce^z  varepsilon  absz  1 \nfracce^z-1z  textrmelse\nendcases\nendequation","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"(Image: Illustration of φ₁ accuracy)","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"The solid line corresponds to the naïve implementation eqrefeqnphi-1-naive, whereas the dashed line corresponds to the accurate implementation eqrefeqnphi-1-accurate.","category":"page"},{"location":"phi_functions/#Accuracy-for-k-1-1","page":"φₖ functions","title":"Accuracy for k  1","text":"","category":"section"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"For a Taylor expansion of a function f(x), we have","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nf(x-a) = underbracesum_i=0^n fracf^(i)(a)i (x-a)^i_defd T_n(x) +\nunderbracefracf^(n+1)(xi)(n+1)(x-a)^n+1_defd R_n(x) quad\nxi in ax\nendequation","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"We now Taylor expand ce^(h-s)z about z=0:","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nce^(h-s)z =\nsum_i=0^n fracz^i(h-s)^ii +\nfracce^(h-s)zetazeta^n+1(h-s)^n+1(n+1)\nquad abszeta leq z\nendequation","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"With this, we now calculate the definite integral appearing in the definition of varphi_k:","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nbeginaligned\nint_0^hdiffs\nce^(h-s)z s^k-1\n=\nint_0^hdiffs\nsum_i=0^n fracz^i(h-s)^is^k-1i +\nint_0^hdiffs\nfracce^(h-s)zetazeta^n+1(h-s)^n+1s^k-1(n+1) \n=\nsum_i=0^n\nfracz^ii\nint_0^hdiffs\n(h-s)^is^k-1 +\nint_0^hdiffs\nfracce^(h-s)zetazeta^n+1(h-s)^n+1s^k-1(n+1)\nendaligned\nendequation","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"For the case we are interested in, h=1 and the first integral is equivalent to Euler's beta function:","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nint_0^1diffs s^k-1(1-s)^i equiv Beta(ki+1) equiv fracGamma(k)Gamma(i+1)Gamma(k+i+1)\nendequation","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"which, for integer ki has the following value","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nBeta(ki+1) = frac(k-1)i(k+i)\nendequation","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"Inserting this into the integral (having set h=1), we find","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"beginequation\nlabeleqnphi-k-expansion\nvarphi_k(z) =\nsum_i=0^n\nfracz^i(k+i)\n+int_0^1diffs R_n(szeta)\nendequation","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"where we have made explicit the dependence of the Lagrange remainder R_n(szeta) on s.","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"Some numerical testing seems to indicate it is enough to set n=k in the Taylor expansion eqrefeqnphi-k-expansion to get accurate evaluation of phi_k(x) for small absx, xinmathbbR. For general z, the amount of required terms seems higher, so n is currently set to 10k.","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"(Image: Illustration of φ₁ accuracy)","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"The plot includes phi_k(z) for kin0100. To illustrate the rounding errors that would occur if one were to use the recursive definition eqrefeqnphi-k-recursive directly , we plot varphi_k(x), but for kin04 only:","category":"page"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"(Image: Illustration of φ₁ accuracy)","category":"page"},{"location":"phi_functions/#Reference-1","page":"φₖ functions","title":"Reference","text":"","category":"section"},{"location":"phi_functions/#","page":"φₖ functions","title":"φₖ functions","text":"MatrixPolynomials.φ₁\nMatrixPolynomials.φ","category":"page"},{"location":"phi_functions/#MatrixPolynomials.φ₁","page":"φₖ functions","title":"MatrixPolynomials.φ₁","text":"φ₁(z)\n\nSpecial case of φ for k=1, taking care to avoid numerical rounding errors for small z.\n\n\n\n\n\n","category":"function"},{"location":"phi_functions/#MatrixPolynomials.φ","page":"φₖ functions","title":"MatrixPolynomials.φ","text":"φ(k, z)\n\nCompute the entire function varphi_k(z), zinmathbbC, which is recursively defined as [Eq. (2.11) of Hochbruck2010]\n\nvarphi_k+1(z) equiv fracvarphi_k(z)-varphi_k(0)z\n\nwith the base cases\n\nvarphi_0(z) = exp(z) quad\nvarphi_1(z) = fracexp(z)-1z\n\nand the special case\n\nvarphi_k(0) = frac1k\n\nThis function, as the base case φ₁, is implemented to avoid rounding errors for small z.\n\n\n\n\n\nφ(k)\n\nReturn a function corresponding to φₖ.\n\nExamples\n\njulia> φ(0)\nexp (generic function with 14 methods)\n\njulia> φ(1)\nφ₁ (generic function with 1 method)\n\njulia> φ(2)\nφ₂ (generic function with 1 method)\n\njulia> φ(15)\nφ₁₅ (generic function with 1 method)\n\njulia> φ(15)(5.0 + im)\n1.0931836313419128e-12 + 9.301475570434819e-14im\n\n\n\n\n\n","category":"function"},{"location":"newton_polynomials/#Newton-polynomials-1","page":"Newton polynomials","title":"Newton polynomials","text":"","category":"section"},{"location":"newton_polynomials/#","page":"Newton polynomials","title":"Newton polynomials","text":"MatrixPolynomials.NewtonPolynomial\nMatrixPolynomials.NewtonPolynomial(f::Function, ζ::AbstractVector)\nMatrixPolynomials.NewtonMatrixPolynomial\nLinearAlgebra.mul!(w, nmp::MatrixPolynomials.NewtonMatrixPolynomial, A, v)\nMatrixPolynomials.φₖResidualEstimator","category":"page"},{"location":"newton_polynomials/#MatrixPolynomials.NewtonPolynomial","page":"Newton polynomials","title":"MatrixPolynomials.NewtonPolynomial","text":"NewtonPolynomial(ζ, d)\n\nThe unique interpolation polynomial of a function in its Newton form, i.e.\n\nf(z) approx p(z) = sum_j=1^m divdiff(zeta_1j)f prod_i=1^j-1(z - zeta_i)\n\nwhere ζ are the interpolation points and d[j]=⏃(ζ[1:j])f is the jth divided difference of the interpolated function f.\n\n\n\n\n\n","category":"type"},{"location":"newton_polynomials/#MatrixPolynomials.NewtonPolynomial-Tuple{Function,AbstractArray{T,1} where T}","page":"Newton polynomials","title":"MatrixPolynomials.NewtonPolynomial","text":"NewtonPolynomial(f, ζ)\n\nConstruct the Newton polynomial interpolating f at ζ, automatically deriving the divided differences using ⏃.\n\n\n\n\n\n","category":"method"},{"location":"newton_polynomials/#MatrixPolynomials.NewtonMatrixPolynomial","page":"Newton polynomials","title":"MatrixPolynomials.NewtonMatrixPolynomial","text":"NewtonMatrixPolynomial(np, pv, r, Ar, error)\n\nThis structure aids in the computation of the action of a matrix polynomial on a vector. np is the NewtonPolynomial, pv is the desired result, r and Ar are recurrence vectors, and error is an optional error estimator algorithm that can be used to terminate the iterations early.\n\n\n\n\n\n","category":"type"},{"location":"newton_polynomials/#LinearAlgebra.mul!-Tuple{Any,MatrixPolynomials.NewtonMatrixPolynomial,Any,Any}","page":"Newton polynomials","title":"LinearAlgebra.mul!","text":"mul!(w, nmp::NewtonMatrixPolynomial, A, v)\n\nCompute the action of the NewtonMatrixPolynomial nmp evaluated for the matrix (or linear operator) A acting on v and storing the result in w, i.e. w ← p(A)*v.\n\n\n\n\n\n","category":"method"},{"location":"newton_polynomials/#MatrixPolynomials.φₖResidualEstimator","page":"Newton polynomials","title":"MatrixPolynomials.φₖResidualEstimator","text":"φₖResidualEstimator{T,k}(nmpd, ρ, vscaled, estimate, tol)\n\nAn implementation of the residual error estimate of the φₖ functions, as presented in\n\nKandolf, P., Ostermann, A., & Rainer, S. (2014). A residual based error estimate for Leja interpolation of matrix functions. Linear Algebra and its Applications, 456(nil), 157–173. DOI: 10.1016/j.laa.2014.04.023\n\nnmpd is a NewtonMatrixPolynomialDerivative that successively computes the time-derivative of the NewtonMatrixPolynomial used to interpolate varphi_k(tA) (the time-step t is subsequently set to unity), ρ is the residual vector, vscaled an auxiliary vector for k>0, and estimate and tol are the estimated error and tolerance, respectively.\n\n\n\n\n\n","category":"type"},{"location":"#MatrixPolynomials.jl-1","page":"Home","title":"MatrixPolynomials.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"","category":"page"}]
}
